{
 "metadata": {
  "name": "",
  "signature": "sha256:876129086b1a3c0e1f5333817829407adb3dd51e21b624bd8cd524ad2e28ad9d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#COM2004/3004 Lab Week 5#\n",
      "\n",
      "#Linear Classification#\n",
      "\n",
      "##Objectives##\n",
      "\n",
      "* To gain some practical experience with linear classification.\n",
      "* To reduce Bayesian classifiers to linear classifiers by constraining the\n",
      "covariances of the classes to be equal.\n",
      "* To compare the performance of a generative model and a discriminative model on\n",
      "a challenging classification task.\n",
      "\n",
      "##1. Background##\n",
      "\n",
      "In today\u2019s lab we will be revisiting the Bayesian classification code that we used last week but we will constrain the system to have equal covariance matrices effectively turning it into a linear classifier. We will then compare this 'generative\u2019 approach with the 'discriminative\u2019 approach that we saw in the lecture on Friday: learning the linear classifier parameters directly by using the perceptron learning algorithm.\n",
      "\n",
      "##2. Introduction##\n",
      "\n",
      "This week we will be using another data set from the UCI machine-learning repository: abalone data. An abalone is a type of see snail. The age of a specimen can be determined by cutting the shell through the cone and counting rings through a microscope (rather like trees), but this is a time consuming and expensive procedure. The task here is to predict the number of rings given simple external measurements of the weight and dimension of the animal. For the data set we are using the real values are known (i.e. the rings were counted after the snails were measured). Results vary from 1 to 29 rings, so this would usually be treated as a 29-class classification problem. To simplify things a little I have regrouped the data into just two classes of roughly equal size: young (less than 10 rings) and old (10 or more rings). I have also only taken the female samples. There are 7 measurements (which are all quite highly correlated) that are to be used to predict the class label. (The precise meaning of the measurements can be found here http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.names)\n",
      "\n",
      "Compared to the wine classification task this task is quite challenging. It will be impossible to get 100% correct because the classes are not linearly separable. Further, most of the specimens have either 8, 9, 10 or 11 rings and so lie close to the young/old borderline. However, you should be able to get percentage correct scores that are considerably higher than the 50% that would be expected by guessing alone.\n",
      "\n",
      "##3. Obtaining the data##\n",
      "\n",
      "The data can be read directly from the web into an numpy array using the code in the cell below. The data will form a matrix with 1,306 rows and 8 columns. Each row is a separate\n",
      "sample (i.e. a different snail). The first column stores a class label (1 or 2). Columns 2 to 8 are the results of the 7 length and weight measurements. Note that, like last week, the features are stored as columns and the samples as rows. This makes things easier when using Python but in our lecture notes and many textbooks the opposite convention is used."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import urllib2\n",
      "X = np.loadtxt(urllib2.urlopen(\"http://staffwww.dcs.shef.ac.uk/people/J.Barker/abalone.dat\",\"r\"))\n",
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##4. Generative modeling: Bayesian classification with equi-covariant multivariate normal distributions.##\n",
      "\n",
      "Compared to last week, there are a lot more samples (1,306 compared with 178) so we will not worry about leave-one-out testing, instead, we will simply cut the data into equal sized testing and training sets like we did for the first half of the lab last week.\n",
      "\n",
      "By adapting the code you wrote last week, evaluate the performance of a Bayesian classifier using multivariate normal distributions with full covariance matrices. When considering changes to the code note that the main difference is that this week there are only two classes rather than three. (If you wish you may trying wrapping the code into a function and seeing if you can design it so that it works for any number of classes.)\n",
      "\n",
      "How well does your classifier perform? (The score will probably be in the 60-70% range for this task, so don\u2019t worry if performance seems a lot poorer than last week)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SOLUTION\n",
      "abalone1 = X[X[:,0]==1,:]\n",
      "abalone2 = X[X[:,0]==2,:]\n",
      "abalone1_test = abalone1[0::2,:]\n",
      "abalone1_train = abalone1[1::2, :]\n",
      "abalone2_test = abalone2[0::2,:]\n",
      "abalone2_train = abalone2[1::2, :]\n",
      "abalone_test = np.vstack((abalone1_test, abalone2_test))\n",
      "abalone_test.shape\n",
      "\n",
      "mean1 = np.mean(abalone1_train[:,1:], axis=0)\n",
      "mean2 = np.mean(abalone2_train[:,1:], axis=0)\n",
      "cov1 = np.cov(abalone1_train[:,1:], rowvar=0)\n",
      "cov2 = np.cov(abalone2_train[:,1:], rowvar=0)\n",
      "\n",
      "from scipy.stats import multivariate_normal\n",
      "dist1 = multivariate_normal(mean=mean1, cov=cov1)\n",
      "dist2 = multivariate_normal(mean=mean2, cov=cov2)\n",
      "\n",
      "p1=dist1.pdf(abalone_test[:,1:])\n",
      "p2=dist2.pdf(abalone_test[:,1:])\n",
      "\n",
      "p = np.vstack((p1,p2))\n",
      "\n",
      "index = np.argmax(p, axis=0)+1\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "plt.plot(index, 'k.', ms=10)\n",
      "\n",
      "correct = abalone_test[:,0]==index\n",
      "percent_correct = np.sum(correct)*100.0/index.shape\n",
      "print(percent_correct)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Using equal covariance matrices.**\n",
      "\n",
      "If you correctly followed the same procedures as last week you will have estimated a separate covariance matrix for each class. These matrices will not be equal and so the system will not have been a linear classifier. In order to reduce it down to a linear system we need to ensure that there is only one covariance matrix. There are different ways that you might imagine doing this:\n",
      "\n",
      "First, you might imagine simply estimating a single covariance matrix from the complete training set before dividing it into classes. This produces a single matrix but it is not the correct thing to do. We want the matrix to represent the spread *within* the classes, if you simply train a model using the full training data set it will also be capturing the spread *between* the classes.\n",
      "\n",
      "Second, you could imagine *averaging* the two class-dependent covariance matrices. This is closer to the correct thing but it doesn\u2019t take care of the fact that the classes might have had unequal numbers of examples. The best approach is to first move the centres of the two classes onto the same point and then treat them as a single class. To move the class centres onto the same point you can simply subtract the class mean vector from each data sample.\n",
      "\n",
      "E.g., for each sample in class one you need to compute,\n",
      "    \n",
      "    abalone1_train (i,:)\u2013 mean1\n",
      "    \n",
      "and for each sample in class two you would compute,\n",
      "    \n",
      "    abalone2_train(i,:) \u2013 mean2\n",
      "\n",
      "You can do this without a loop. In fact you can just type\n",
      "  \n",
      "    abalone2_train - mean1\n",
      "  \n",
      "When numpy sees a vector being subtracted from a matrix like this, it will automatically copy the vector so that it is subtracted from every row of the matrix (this is called 'broadcasting').\n",
      "\n",
      "Go ahead and modify your code so that a single covariance matrix is computed called, for example, cov_global."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SOLUTION\n",
      "\n",
      "def centre_data(data):\n",
      "    nsamples = data.shape[0]\n",
      "    data_mean = np.mean(data, axis=0)\n",
      "    data_centred = data - data_mean\n",
      "    return data_centred\n",
      "\n",
      "abalone1_centred = centre_data(abalone1_train)\n",
      "abalone2_centred = centre_data(abalone2_train)\n",
      "\n",
      "abalone_centred = np.vstack((abalone1_centred, abalone2_centred))\n",
      "\n",
      "cov_global = np.cov(abalone_centred[:,1:], rowvar=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can now redo the classification using this single matrix in both mvnpdf evaluations\n",
      "    \n",
      "    p1 = mvnpdf(abalone1_test, mean1, cov_global);\n",
      "    p2 = mvnpdf(abalone2_test, mean2, cov_global);\n",
      "    etc\n",
      "\n",
      "What is the new result? How does it compare with the result when using the more flexible non-linear classifer (i.e. when using two different covariance matrices)?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dist1 = multivariate_normal(mean=mean1, cov=cov_global)\n",
      "dist2 = multivariate_normal(mean=mean2, cov=cov_global)\n",
      "\n",
      "p1=dist1.pdf(abalone_test[:,1:])\n",
      "p2=dist2.pdf(abalone_test[:,1:])\n",
      "\n",
      "p = np.vstack((p1,p2))\n",
      "\n",
      "index = np.argmax(p, axis=0)+1\n",
      "\n",
      "plt.plot(index, 'k.', ms=10)\n",
      "\n",
      "correct = abalone_test[:,0]==index\n",
      "percent_correct = np.sum(correct)*100.0/index.shape\n",
      "print(percent_correct)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we wished we could represent this linear Gaussian classifier in the standard linear classifier form, i.e. $g(x) = w\u2019x+w_0$ and output $\\omega_1$ if $g(x)>0$ else $\\omega_2$. The parameters $w\u2019$ and $w_0$ would simply be a function of the covariance matrix and the class means that we have learnt from the training data. Actually, although this would involve an extra bit of calculation, once we had computed $w\u2019$ and $w_0$, all the test points could be classified very quickly by evaluating $g(x)$ directly (e.g., for an $N$-dimension problem this amounts to just $N+1$ multiplications, $N$ additions and a comparison against 0).\n",
      "\n",
      "##5. Disciminative modeling: the Perceptron learning algorithm##\n",
      "\n",
      "In the 2nd half of the lab we turn to look at a discriminative approach to classification in which the $w$ parameters needed for the evaluation of $g(x)$ are learnt directly. We will use the perceptron learning algorithm that was presented in the lecture last week.\n",
      "\n",
      "The perceptron learning algorithm is quite easy to implement, but in order to save time I\u2019ve provided an implementation for you below. The function has several inputs: training data, training_labels, an initial guess at the weights and a learning rate. **Note, the class labels have to be given the values +1 and -1 for the two classes**. It will return a tuple containing, i) learnt w parameters, ii) the number of iterations performed, iii) the number of misclassfied samples. \n",
      "\n",
      "Take some time to examine the code. Don\u2019t worry if it is not immediately clear how each line is working, but just satisfy yourself that you understand what each line is meant to be doing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def perce(X, y, w_init, rho):\n",
      "    \"\"\" perce\n",
      "    A simple but inefficient implementation of the perceptron learning alogorithm\n",
      "\n",
      "    X - the data matrix. Each row represents a separate sample\n",
      "    y - a vector of integer class labels corresponding to the rows of X - labels must be +1 or -1\n",
      "    w_init - the initial weight vector \n",
      "    rho - a scalar learning rate\n",
      "    \"\"\"\n",
      "\n",
      "    (N, nfeatures) = X.shape\n",
      "    \n",
      "    # Augment the feature vectors by adding a 1 to each one. (see lecture notes)\n",
      "    X = np.hstack((X, np.ones((N,1))))\n",
      "    nfeatures += 1\n",
      "    \n",
      "    max_iter = 100  # maximum number of iterations\n",
      "    w = w_init      # initialise weights\n",
      "    iter = 0      \n",
      "    mis_class = N   # start by assuming all samples are misclassified\n",
      "\n",
      "    while mis_class > 0 and iter < max_iter:\n",
      "        iter += 1\n",
      "        mis_class = 0\n",
      "        gradient = np.zeros((1,nfeatures)) # initaliase the gradients to 0\n",
      "        \n",
      "        # loop over every training sample. \n",
      "        for i in xrange(N):\n",
      "            # each misclassified point will cause the gradient to change\n",
      "            if np.inner(X[i,:], w)*y[i] >= 0:\n",
      "                mis_class += 1\n",
      "                gradient += y[i] * X[i,:]\n",
      "        # update the weight vector ready for the next iteration        \n",
      "        w -= rho*gradient\n",
      "        \n",
      "    return w, iter, mis_class"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The implementation above is quite straightforward. The lines of code should correspond quite closely to the description in the lecture notes. Unfortunately, the inner loop over the samples is very slow. This is largely because Python is an interpretted language. We can speed it up by processing all the points at the same time by using matrix operations than are processed by numpy. The improved implementation is shown below. Note how the inner loop has now 'vanished'. This version runs 100 times faster! Noe that the max_iter has been set to 10000 rather than 100 so that up to 100 times as many iteraions may be performed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def perce_fast(X, y, w_init, rho):\n",
      "    \"\"\" perce_fast\n",
      "    A more efficient implementation of the perceptron alogorithm\n",
      "    For the lab class data this version will work x100 faster!\n",
      "\n",
      "    X - the data matrix. Each row represents a separate sample\n",
      "    y - a vector of integer class labels corresponding to the rows of X - labels must be +1 or -1\n",
      "    w_init - the initial weight vector \n",
      "    rho - a scalar learning rate\n",
      "    \"\"\"\n",
      "    (N, nfeatures) = X.shape\n",
      "    X = np.hstack((X, np.ones((N,1))))\n",
      "    nfeatures += 1\n",
      "    max_iter = 10000\n",
      "    w = w_init\n",
      "    iter = 0\n",
      "    mis_class = N\n",
      "    yy = np.tile(y, (1, nfeatures))\n",
      "    while mis_class > 0 and iter < max_iter:\n",
      "        iter += 1\n",
      "        mis_class = 0\n",
      "        gradient = np.zeros((1,nfeatures))\n",
      "        mc = ((np.dot(X, w.transpose()) * y) >= 0)[:,0]\n",
      "        mis_class = np.sum(mc)\n",
      "        w -= rho * (np.sum(yy[mc, :] * X[mc, :], axis=0))\n",
      "    return w, iter, mis_class"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now use perceptron function with the same training data that you used previously in order to learn the weights. You will need to read the documentation at the head of the function so that you understand what inputs are required. In particular, note that the class labels have to be in the form of a vector storing -1\u2019s and +1\u2019s. So you will have to manipulate your training data a little because it currently has the classes labeled represented as 1 and 2.\n",
      "\n",
      "Experiment with different learning rates and different numbers of iterations. The function returns the number of errors that are made on the training set. You want this number to be as low as possible."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SOLUTION\n",
      "abalone_train = np.vstack((abalone1_train, abalone2_train))\n",
      "abalone_train_data = abalone_train[:, 1:]\n",
      "abalone_train_labels = np.array([abalone_train[:, 0]]).transpose() * 2 - 3\n",
      "\n",
      "#rho = 1\n",
      "#w_init = np.zeros((1, abalone_train_data.shape[1]+1))\n",
      "#w, iter, mis_class = perce(abalone_train_data, abalone_train_labels, w_init, rho)\n",
      "#print(w)\n",
      "#print(mis_class)\n",
      "\n",
      "rho = 0.1\n",
      "w_init = np.zeros((1, abalone_train_data.shape[1]+1))\n",
      "w, iter, mis_class = perce_fast(abalone_train_data, abalone_train_labels, w_init, rho)\n",
      "print(w)\n",
      "print(mis_class)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Evaluating the classifier:** You now need to evaluate the $w$ vector that the learning algorithm has produced. To do this you will need to evaluate $w\u2019x+w_0$ for each element in the test set and generate a label by comparing the result against 0. Then compute the percentage of labels that match the correct test set labels. It is probably best to write a little function to do this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SOLUTION\n",
      "\n",
      "# Make test data and test labels\n",
      "abalone_test = np.vstack((abalone1_test, abalone2_test))\n",
      "abalone_test_data = abalone_test[:, 1:]\n",
      "abalone_test_labels = np.array([abalone_test[:, 0]]).transpose() * 2 - 3\n",
      "\n",
      "# Perform classification - copied from perce_fast\n",
      "X = abalone_test_data\n",
      "(N, nfeatures) = X.shape\n",
      "X = np.hstack((X, np.ones((N,1))))\n",
      "mc = ((np.dot(X, w.transpose()) * abalone_test_labels) >= 0)[:,0]\n",
      "mis_class = np.sum(mc)\n",
      "\n",
      "# Convert number of miss classifications into percentage correct\n",
      "print 100.0 - mis_class*100.0/N\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How well does the new classifier perform? How does performance compare with the linear classifier that you built using Gaussians in the first half of the lab?\n",
      "\n",
      "##6. Notes##\n",
      "\n",
      "You should find that although the new classifier is again linear, its performance is a little better. You might be confused about this because in lectures we previously spoke about Bayesian classifiers being optimal \u2013 their decision boundaries are positioned so as to minimize the number of classification errors. However, this is only true in the theoretical sense that they are optimal if we use the correct distribution for $p(x|w)$. In practice we don\u2019t know this distribution so we estimate it from the training data. This is typically done by assuming $p(x|w)$ has some general shape (e.g. Gaussian) and then estimating specific parameters, e.g. means and covariances, that best fits the training data. This would be fine is our initial assumption was correct, but the fact is that the data is very unlikely to fit some nice well-behaved distribution like a Gaussian. For example, it might be approximately Gaussian but slightly skewed, or with slightly elongated tails etc etc. So even with the best possible parameter tuning there will still exist a discrepancy between the $p(x|w)$ that we\u2019ve estimated and the true distribution. If we aren\u2019t using the correct $p(x|w)$ then all bets are off and we can\u2019t guarantee that the model we have chosen will be the one that minimizes errors.\n",
      "\n",
      "The discriminative approach on the other hand is doing something that is closer to directly minimizing errors. It is doing this without regard to the distribution of $p(x|w)$. This more pragmatic approach often works better particularly in cases where $p(x|w)$ has a complicated distribution that is hard to parameterize. It is also perhaps closer to what we do as humans, e.g. we are often not aware of small differences within classes (e.g. in speech, all \u2018b\u2019 phonemes sound roughly similar) but we are very sensitive to small changes at the borders between classes (\u2018b\u2019 and \u2018p\u2019 are perceptually quite different, but if you look at features extracted from their sound signals they can be extremely similar).\n",
      "\n",
      "#Programming Challenge#\n",
      "\n",
      "##7. Programming exercise##\n",
      "\n",
      "In the lecture notes two versions of the Perceptron learning algorithm are discussed. The first works in batch mode like the code you have used here, i.e. all points are first classified and then the weights are updated. The second, works in an online mode and processes thee samples one at a time, i.e. the w parameters are adjusted directly after processing each sample.\n",
      "Copy the function perce() into the cell below and then rewrite it so that it works in the online manner. (Note, unfortunately, the fast version perce_fast cannot be made to run in an online manner because it gets its speed precisely because it processes all samples in one step.) the Does it produces better results for the Abalone task? I haven\u2019t tried this myself, so I will be interested to hear the result if anyone gets this far."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}